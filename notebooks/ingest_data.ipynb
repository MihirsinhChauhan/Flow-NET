{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame, target_size=(100, 100)):\n",
    "    \"\"\"\n",
    "    Preprocess a single frame:\n",
    "    - Resize to target size\n",
    "    - Convert to grayscale\n",
    "    \"\"\"\n",
    "    # Resize frame\n",
    "    frame_resized = cv2.resize(frame, target_size)\n",
    "    # Convert to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "    return frame_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from label names to numerical values\n",
    "label_map = {'HAS': 0, 'LAS': 1, 'Plug': 2}\n",
    "\n",
    "\n",
    "def load_frames_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Load frames from a folder and preprocess them.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get list of image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            # Read image\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            frame = cv2.imread(image_path)\n",
    "            if frame is None:\n",
    "                continue\n",
    "            \n",
    "            # Preprocess frame\n",
    "            processed_frame = preprocess_frame(frame)\n",
    "            \n",
    "            # Extract label from folder name\n",
    "            label_name = os.path.basename(folder_path)\n",
    "            label = label_map.get(label_name)\n",
    "            if label is None:\n",
    "                continue\n",
    "            # Append processed frame and label to lists\n",
    "            frames.append(processed_frame)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image '{image_file}': {e}\")\n",
    "    \n",
    "    return frames, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to load frames from three folders\n",
    "def load_frames_main(data_folders):\n",
    "    all_frames = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for folder in data_folders:\n",
    "        frames, labels = load_frames_from_folder(folder)\n",
    "        all_frames.extend(frames)\n",
    "        all_labels.extend(labels)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_frames = np.array(all_frames)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    return all_frames, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frames array: (12589, 100, 100)\n",
      "Unique labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# List of folders containing frames, each representing a different class\n",
    "\n",
    "data_folder_HAS = '../../Two Phase Data/HAS'\n",
    "data_folder_LAS = '../../Two Phase Data/LAS'\n",
    "data_folder_Plug = '../../Two Phase Data/Plug'\n",
    "\n",
    "data_folders = [data_folder_HAS, data_folder_LAS, data_folder_Plug]\n",
    "\n",
    "# Load frames and labels from folders\n",
    "frames, labels = load_frames_main(data_folders)\n",
    "\n",
    "# Check the shape of the loaded frames array\n",
    "print(\"Shape of frames array:\", frames.shape)\n",
    "\n",
    "# Check the unique labels\n",
    "print(\"Unique labels:\", np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 8056\n",
      "Number of samples in validation set: 2015\n",
      "Number of samples in test set: 2518\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(frames, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets (80% training, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert numpy arrays to TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "# Optionally shuffle and batch the datasets\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "# Print the number of samples in each dataset\n",
    "print(\"Number of samples in training set:\", len(X_train))\n",
    "print(\"Number of samples in validation set:\", len(X_val))\n",
    "print(\"Number of samples in test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define file paths to save the preprocessed data\n",
    "train_data_path = '../data/train_data.npz'\n",
    "val_data_path = '../data/val_data.npz'\n",
    "test_data_path = '../data/test_data.npz'\n",
    "\n",
    "# Save the preprocessed data as NumPy arrays\n",
    "np.savez(train_data_path, frames=X_train, labels=y_train)\n",
    "np.savez(val_data_path, frames=X_val, labels=y_val)\n",
    "np.savez(test_data_path, frames=X_test, labels=y_test)\n",
    "\n",
    "print(\"Preprocessed data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
